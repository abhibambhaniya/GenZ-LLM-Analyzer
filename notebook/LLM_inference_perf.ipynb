{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "# Set up interactive widgets for the variables\n",
    "from ipywidgets import interact, IntSlider, Checkbox, BoundedIntText, BoundedFloatText, Dropdown\n",
    "import ipywidgets as widgets\n",
    "\n",
    "\n",
    "# Max Batch Size\n",
    "def create_interactive_widget():\n",
    "    # Quantization dropdown\n",
    "    graph_type = widgets.Dropdown(\n",
    "        options=[\n",
    "            ('1. ISO-HW: Model vs Throughput', 1),\n",
    "            ('2. ISO-HW: Model vs Latency (TTFT, TPOT)', 2),\n",
    "            ('3. ISO-HW, ISO-Model: Batch vs Throughput/Latency', 3) ],\n",
    "        value=3,\n",
    "        description='Graph Type:',\n",
    "        disabled=False ,\n",
    "        layout=widgets.Layout(width='500px'),  # Adjust this value as needed\n",
    "        style={'description_width': 'initial'},\n",
    "\n",
    "    )\n",
    "    max_batch_size = widgets.BoundedIntText(\n",
    "        value=8, min=1, max=128, step=1,\n",
    "        description='Max Batch Size:',\n",
    "        disabled=False ,\n",
    "        layout=widgets.Layout(width='150px'),  # Adjust this value as needed\n",
    "        style={'description_width': 'initial'}\n",
    "    )\n",
    "\n",
    "    # Custom Usecases\n",
    "    usecases = Dropdown( options=['Ques-Ans', 'Text Summarization', 'Chatbots', 'Code Gen.', 'Custom'], value='Chatbots', description='Usecases:', disabled=False,)\n",
    "\n",
    "    # Beam size\n",
    "    beam_size = widgets.IntSlider(value=2, min=1, max=16, description='# of Parallel Beams:', style={'description_width': 'initial'},)\n",
    "\n",
    "    # Input Tokens\n",
    "    input_tokens = widgets.BoundedIntText(\n",
    "        value=2048, min=1, max= 100000, step=1,\n",
    "        description='Input Tokens:',\n",
    "        disabled=False ,\n",
    "        layout=widgets.Layout(width='150px'),  # Adjust this value as needed\n",
    "        style={'description_width': 'initial'}\n",
    "    )\n",
    "\n",
    "    # Output Tokens\n",
    "    output_tokens = widgets.BoundedIntText(\n",
    "        value=128, min=1, max= 100000, step=1,\n",
    "        description='Output Tokens:',\n",
    "        disabled=False ,\n",
    "        layout=widgets.Layout(width='150px'),  # Adjust this value as needed\n",
    "        style={'description_width': 'initial'}\n",
    "    )\n",
    "\n",
    "    # Quantization dropdown\n",
    "    quantization = widgets.Dropdown(\n",
    "        options=['fp8', 'bf16', 'int8', 'int4', 'int2', 'fp32'],\n",
    "        value='int8',\n",
    "        description='Quantization:',\n",
    "        disabled=False ,\n",
    "        layout=widgets.Layout(width='150px'),  # Adjust this value as needed\n",
    "        style={'description_width': 'initial'},\n",
    "\n",
    "    )\n",
    "    model_box = widgets.SelectMultiple( options=[\n",
    "        ('meta-llama/Llama-2-7B','llama2_7b'),\n",
    "        ('meta-llama/Meta-Llama-3-8B','llama3_8b'),\n",
    "        ('meta-llama/Llama-2-13B','llama2_13b'),\n",
    "        ('meta-llama/Llama-2-70B','LLaMA2_70b'),\n",
    "        ('meta-llama/Meta-Llama-3.1-405B', 'llama_405b'),\n",
    "        ('google/gemma-2B','gemma_2b'),\n",
    "        ('google/gemma-7B','gemma_7b'),\n",
    "        ('google/gemma-2-9B','gemma2_9b'),\n",
    "        ('google/gemma-2-27B','gemma2_27b'),\n",
    "        ('mistralai/mistral-7B', 'mistral_7b'),\n",
    "        ('mistralai/Mixtral-8x7B','mixtral_8x7b'),\n",
    "        ('microsoft/phi3mini', 'phi3mini'),\n",
    "        ('microsoft/phi3small', 'phi3small'),\n",
    "        ('microsoft/phi3medium', 'phi3medium'),\n",
    "        ('databricks/dbrx-base','dbrx'),\n",
    "        ('xai-org/grok-1','grok-1'),\n",
    "        ('openai/gpt-3','gpt-3'),\n",
    "        ('openai/gpt-4','gpt-4'),\n",
    "        ('facebook/opt-125m','opt_125m'),\n",
    "        ('facebook/opt-350m','opt_350m'),\n",
    "        ('facebook/opt-1.3b','opt_1b'),\n",
    "        ('facebook/opt-175b','opt_175b'),\n",
    "        ], value=['llama2_7b'],\n",
    "        description='Models:',\n",
    "        disabled=False,\n",
    "        layout=widgets.Layout(width='300px', height='150px'))\n",
    "    # System\n",
    "    system = Dropdown( options=['A100_40GB_GPU', 'A100_80GB_GPU', 'H100_GPU','GH200_GPU', 'TPUv4','TPUv5e', 'MI300X', 'Gaudi3', 'Custom'], value='H100_GPU', description='System:', disabled=False,)\n",
    "\n",
    "    # Number of Nodes\n",
    "    nodes = widgets.IntText(\n",
    "        value=2,\n",
    "        description='# Nodes:',\n",
    "        layout=widgets.Layout(width='150px'),  # Adjust this value as needed\n",
    "        disabled=False\n",
    "    )\n",
    "\n",
    "    # System Efficiency\n",
    "    system_efficiency = widgets.FloatSlider(\n",
    "        value=0.80,\n",
    "        min=0,\n",
    "        max=1.0,\n",
    "        step=0.01,\n",
    "        description='System Efficiency:',\n",
    "        disabled=False,\n",
    "        continuous_update=False,\n",
    "        orientation='horizontal',\n",
    "        readout=True,\n",
    "        readout_format='.2f',\n",
    "    )\n",
    "\n",
    "\n",
    "    # FLOPS (initially hidden)\n",
    "    flops = widgets.FloatText(value=1000,description='FLOPS(T):',disabled=False, layout=widgets.Layout(width='200px'),)\n",
    "    # MEM BW (initially hidden)\n",
    "    mem_bw = widgets.FloatText(value=3.6,description='MEM BW(TB/s):',disabled=False, layout=widgets.Layout(width='200px'),)\n",
    "    # FLOPS (initially hidden)\n",
    "    mem_cap = widgets.FloatText(value=48,description='FLOPS(GBs):',disabled=False, layout=widgets.Layout(width='200px'),)\n",
    "    # ICN BW (initially hidden)\n",
    "    icn_bw = widgets.FloatText(value=100.0,description='ICN BW(GB/s):',disabled=False, layout=widgets.Layout(width='200px'),)\n",
    "\n",
    "\n",
    "    # Function to show/hide FLOPS and MEM BW\n",
    "    def update_visibility_system_param(change):\n",
    "        if 'Custom' in change['new']:\n",
    "            flops.layout.display = ''\n",
    "            mem_bw.layout.display = ''\n",
    "            mem_cap.layout.display = ''\n",
    "            icn_bw.layout.display = ''\n",
    "        else:\n",
    "            flops.layout.display = 'none'\n",
    "            mem_bw.layout.display = 'none'\n",
    "            mem_cap.layout.display = 'none'\n",
    "            icn_bw.layout.display = 'none'\n",
    "\n",
    "    # Connect the function to the models widget\n",
    "    system.observe(update_visibility_system_param, names='value')\n",
    "\n",
    "    # Function to show/hide FLOPS and MEM BW\n",
    "    def update_visibility_usecases(change):\n",
    "        if 'Ques-Ans' in change['new']:\n",
    "            beam_size.value = 4\n",
    "            input_tokens.value = 1000\n",
    "            output_tokens.value = 200\n",
    "        elif 'Text Summarization' in change['new']:\n",
    "            beam_size.value = 4\n",
    "            input_tokens.value = 15000\n",
    "            output_tokens.value = 1000\n",
    "        elif 'Chatbots' in change['new']:\n",
    "            beam_size.value = 2\n",
    "            input_tokens.value = 2048\n",
    "            output_tokens.value = 128\n",
    "        elif 'Code Gen.' in change['new']:\n",
    "            beam_size.value = 4\n",
    "            input_tokens.value = 20000\n",
    "            output_tokens.value = 50\n",
    "\n",
    "    # Connect the function to the models widget\n",
    "    usecases.observe(update_visibility_usecases, names='value')\n",
    "\n",
    "    # # Initially hide custom params\n",
    "    # beam_size.layout.display = 'none'\n",
    "    # input_tokens.layout.display = 'none'\n",
    "    # output_tokens.layout.display = 'none'\n",
    "\n",
    "    flops.layout.display = 'none'\n",
    "    mem_bw.layout.display = 'none'\n",
    "    mem_cap.layout.display = 'none'\n",
    "    icn_bw.layout.display = 'none'\n",
    "\n",
    "    # Layout\n",
    "    left_box = widgets.HBox([quantization, max_batch_size])\n",
    "    input_param_box = widgets.VBox([usecases, beam_size,widgets.HBox([ input_tokens, output_tokens])])\n",
    "    top_box = widgets.VBox([left_box, input_param_box, ])\n",
    "    bottom_box = widgets.HBox([system, nodes, system_efficiency])\n",
    "    system_bottom_box = widgets.HBox([flops, mem_bw, mem_cap, icn_bw])\n",
    "\n",
    "\n",
    "    # Final layout\n",
    "    final_layout = widgets.VBox([graph_type, widgets.HBox([model_box,top_box]), bottom_box, system_bottom_box], layout=widgets.Layout(justify_content='space-between'))\n",
    "\n",
    "    output = widgets.interactive_output(generate_demand_curve,\n",
    "                                        dict(\n",
    "        graph_type = graph_type,\n",
    "        system_box = system,\n",
    "        system_eff = system_efficiency,\n",
    "        num_nodes_slider = nodes,\n",
    "        model_box=model_box,\n",
    "        quantization_box=quantization,\n",
    "        batch_slider=max_batch_size,\n",
    "        input_token_slider=input_tokens,\n",
    "        output_token_slider=output_tokens,\n",
    "        beam_size = beam_size,\n",
    "        flops=flops,\n",
    "        mem_bw=mem_bw,\n",
    "        mem_cap=mem_cap,\n",
    "        icn_bw=icn_bw))\n",
    "    clear_output(wait=True)\n",
    "    display(final_layout, output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TTFT, TPOT, RPS, Latency, \n",
    "1. ISO-HW: Model vs Throughput\n",
    "2. ISO-HW: Model vs Latency (TTFT, TPOT)\n",
    "3. ISO-HW, ISO-Model: Batch vs Throughput/Latency\n",
    "4. \n",
    "## Website support\n",
    "## A visulaization of the system being modelled\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "456c892ec90f4e4ca3f3f2dac24e6e9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Dropdown(description='Graph Type:', index=2, layout=Layout(width='500px'), options=(('1. ISO-HWâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "785dc055981948c38728c2a32fccdf70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = create_interactive_widget()\n",
    "display(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genz_test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
